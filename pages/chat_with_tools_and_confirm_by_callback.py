import streamlit as st
from openai import OpenAI
import json
import itertools


client = OpenAI()

# Example dummy function hard coded to return the same weather
# In production, this could be your backend API or an external API
def get_current_weather(location, unit="fahrenheit"):
    """Get the current weather in a given location"""
    if "tokyo" in location.lower():
        return json.dumps({"location": "Tokyo", "temperature": "10", "unit": unit})
    elif "san francisco" in location.lower():
        return json.dumps({"location": "San Francisco", "temperature": "72", "unit": unit})
    elif "paris" in location.lower():
        return json.dumps({"location": "Paris", "temperature": "22", "unit": unit})
    else:
        return json.dumps({"location": location, "temperature": "unknown"})

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    },
                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                },
                "required": ["location"],
            },
        },
    }
]
TOOL_HOOKS = {
    "get_current_weather": get_current_weather,
}

def chat_stream(messages, model="gpt-3.5-turbo", tools=[], **kargs):
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        tools=tools if tools else None,
        stream=True,
        **kargs
    )
    tool_calls = []
    for chunk in response:
        if chunk and chunk.choices:
            delta = chunk.choices[0].delta
            if delta.tool_calls:
                tcchunklist = delta.tool_calls
                for tcchunk in tcchunklist:
                    if len(tool_calls) <= tcchunk.index:
                        tool_calls.append({"id": "", "type": "function", "function": { "name": "", "arguments": "" } })
                    tc = tool_calls[tcchunk.index]
                    if tcchunk.id:
                        tc["id"] += tcchunk.id
                    if tcchunk.function.name:
                        tc["function"]["name"] += tcchunk.function.name
                    if tcchunk.function.arguments:
                        tc["function"]["arguments"] += tcchunk.function.arguments
            elif delta.content:
                yield delta.content
    if tool_calls:
        yield tool_calls

# å›žè°ƒå‡½æ•°ï¼šç¡®è®¤å·¥å…·è°ƒç”¨
def confirm_tool_call():
    tool_calls = st.session_state.pending_tool_calls
    
    # å°†å·¥å…·è°ƒç”¨æ·»åŠ åˆ°èŠå¤©åŽ†å²
    st.session_state.chat_history.append({"role": "assistant", "content": "", "tool_calls": tool_calls})
    
    # æ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨å¹¶å­˜å‚¨ç»“æžœ
    for tool_call in tool_calls:
        function_name = tool_call["function"]["name"]
        function_args = json.loads(tool_call["function"]["arguments"])
        function_response = TOOL_HOOKS[function_name](**function_args)
        
        # å­˜å‚¨å·¥å…·è°ƒç”¨ç»“æžœ
        st.session_state.tool_responses.append({
            "tool_call_id": tool_call["id"],
            "function_name": function_name,
            "function_args": function_args,
            "function_response": function_response
        })
        
        # å°†å·¥å…·å“åº”æ·»åŠ åˆ°èŠå¤©åŽ†å²
        st.session_state.chat_history.append({
            "tool_call_id": tool_call["id"],
            "role": "tool",
            "name": function_name,
            "content": function_response,
        })
    
    # æ ‡è®°éœ€è¦èŽ·å–AIçš„åŽç»­å“åº”
    st.session_state.need_ai_response = True
    # æ¸…é™¤å¾…ç¡®è®¤çš„å·¥å…·è°ƒç”¨
    st.session_state.pending_tool_calls = None

# å›žè°ƒå‡½æ•°ï¼šæ‹’ç»å·¥å…·è°ƒç”¨
def reject_tool_call():
    st.session_state.chat_history.append({"role": "assistant", "content": "æ‚¨æ‹’ç»äº†å·¥å…·è°ƒç”¨ï¼Œæˆ‘å°†å°è¯•ä¸ä½¿ç”¨å·¥å…·æ¥å›žç­”æ‚¨çš„é—®é¢˜ã€‚"})
    st.session_state.pending_tool_calls = None
    # ä¸éœ€è¦èŽ·å–AIçš„åŽç»­å“åº”
    st.session_state.need_ai_response = False

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = [{"role": "assistant", "content": "How can I help you?"}]
    
# åˆå§‹åŒ–å¾…ç¡®è®¤çš„å·¥å…·è°ƒç”¨çŠ¶æ€
if "pending_tool_calls" not in st.session_state:
    st.session_state["pending_tool_calls"] = None

# åˆå§‹åŒ–å·¥å…·å“åº”çŠ¶æ€
if "tool_responses" not in st.session_state:
    st.session_state["tool_responses"] = []

# åˆå§‹åŒ–æ˜¯å¦éœ€è¦AIå“åº”çš„çŠ¶æ€
if "need_ai_response" not in st.session_state:
    st.session_state["need_ai_response"] = False

# åˆå§‹åŒ–æ˜¯å¦æœ‰æ–°æ¶ˆæ¯çŠ¶æ€
if "has_new_message" not in st.session_state:
    st.session_state["has_new_message"] = False

# é¡µé¢æ ‡é¢˜
st.title("ðŸ’¬ Chatbot")
st.caption("ðŸš€ A streamlit chatbot powered by OpenAI LLM")

# ä¾§è¾¹æ 
with st.sidebar:
    show_history = st.checkbox('Show history', False)
    if st.button("Reset history"):
        st.session_state.chat_history = [{"role": "assistant", "content": "How can I help you?"}]
        st.session_state.pending_tool_calls = None
        st.session_state.tool_responses = []
        st.session_state.need_ai_response = False
        st.session_state.has_new_message = False

# æ˜¾ç¤ºå¯¹è¯åŽ†å²
for msg in st.session_state.chat_history:
    st.chat_message(msg["role"]).write(msg["content"])

# ç”¨æˆ·è¾“å…¥å¤„ç†
if prompt := st.chat_input():
    st.session_state.has_new_message = True
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

# å¦‚æžœæœ‰æ–°æ¶ˆæ¯ä¸”æ²¡æœ‰å¾…å¤„ç†çš„å·¥å…·è°ƒç”¨ï¼Œåˆ™èŽ·å–AIå“åº”
if st.session_state.has_new_message and not st.session_state.pending_tool_calls:
    # èŽ·å–AIå“åº”
    response = chat_stream(st.session_state.chat_history, tools=tools)
    first_item = next(response)
    
    if isinstance(first_item, list):
        # å·¥å…·è°ƒç”¨ï¼Œå­˜å‚¨ä»¥å¾…ç¡®è®¤
        st.session_state.pending_tool_calls = first_item
    else:
        # æ™®é€šæ¶ˆæ¯ï¼Œç›´æŽ¥æ˜¾ç¤º
        with st.chat_message("assistant"):
            response_messages = st.write_stream(itertools.chain([first_item], response))
        st.session_state.chat_history.append({"role": "assistant", "content": response_messages})
    
    # é‡ç½®æ–°æ¶ˆæ¯æ ‡å¿—
    st.session_state.has_new_message = False

# æ˜¾ç¤ºå·¥å…·è°ƒç”¨çš„ç»“æžœï¼ˆå¦‚æžœæœ‰ï¼‰
if st.session_state.tool_responses:
    # æ˜¾ç¤ºæœ€æ–°ä¸€è½®çš„å·¥å…·å“åº”
    for tool_response in st.session_state.tool_responses:
        with st.chat_message("tool", avatar='ðŸ› ï¸'):
            with st.status(f"è°ƒç”¨å·¥å…·: {tool_response['function_name']} ä½¿ç”¨å‚æ•°: {tool_response['function_args']}"):
                st.write(tool_response['function_response'])
    
    # æ¸…é™¤å·²æ˜¾ç¤ºçš„å·¥å…·å“åº”
    st.session_state.tool_responses = []

# èŽ·å–AIçš„åŽç»­å“åº”ï¼ˆå¦‚æžœéœ€è¦ï¼‰
if st.session_state.need_ai_response:
    with st.chat_message("assistant"):
        stream = chat_stream(st.session_state.chat_history, tools=[])
        response_messages = st.write_stream(stream)
    
    # æ·»åŠ AIå“åº”åˆ°èŠå¤©åŽ†å²
    st.session_state.chat_history.append({"role": "assistant", "content": response_messages})
    # é‡ç½®çŠ¶æ€
    st.session_state.need_ai_response = False

# å¤„ç†å¾…ç¡®è®¤çš„å·¥å…·è°ƒç”¨
if st.session_state.pending_tool_calls:
    with st.chat_message("assistant"):
        st.write("æˆ‘éœ€è¦ä½¿ç”¨å·¥å…·æ¥å›žç­”æ‚¨çš„é—®é¢˜ã€‚è¯·ç¡®è®¤ä»¥ä¸‹å·¥å…·è°ƒç”¨ï¼š")
        
        for tool_call in st.session_state.pending_tool_calls:
            function_name = tool_call["function"]["name"]
            function_args = json.loads(tool_call["function"]["arguments"])
            
            tool_info = f"**å·¥å…·**: {function_name}"
            args_info = f"**å‚æ•°**: {json.dumps(function_args, ensure_ascii=False, indent=2)}"
            
            st.info(f"{tool_info}\n\n{args_info}")
    
    # æ˜¾ç¤ºç¡®è®¤å’Œæ‹’ç»æŒ‰é’®
    col1, col2 = st.columns(2)
    with col1:
        st.button("ç¡®è®¤è°ƒç”¨", key="confirm_tool_call", type="primary", on_click=confirm_tool_call)
    
    with col2:
        st.button("æ‹’ç»è°ƒç”¨", key="reject_tool_call", on_click=reject_tool_call)

if show_history:
    st.write(st.session_state.chat_history)
